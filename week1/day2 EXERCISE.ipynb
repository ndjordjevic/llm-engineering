{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling dde5aa3fc5ff... 100% ▕████████████████▏ 2.0 GB                         \n",
      "pulling 966de95ca8a6... 100% ▕████████████████▏ 1.4 KB                         \n",
      "pulling fcc5a6bec9da... 100% ▕████████████████▏ 7.7 KB                         \n",
      "pulling a70ff7e570d9... 100% ▕████████████████▏ 6.0 KB                         \n",
      "pulling 56bb8bd477a5... 100% ▕████████████████▏   96 B                         \n",
      "pulling 34bb5ab01051... 100% ▕████████████████▏  561 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Creation**: Generative AI can be used to create high-quality content such as articles, social media posts, and videos. For example, AI-powered writing tools like WordLift or Content Blossom can generate optimized blog posts, product descriptions, and more.\n",
      "2. **Image and Video Generation**: Generative AI can be used to create realistic images and videos, such as generating product images, creating virtual try-on experiences, or producing animated explainer videos.\n",
      "3. **Product Design**: Generative AI can assist in designing new products by generating 3D models, prototypes, and even entire product lines. For example, companies like IKEA use generative AI to design furniture and other home decor items.\n",
      "4. **Music Composition**: Generative AI can be used to create original music tracks, beats, or sound effects for various applications such as film, video games, or advertising.\n",
      "5. **Marketing Automation**: Generative AI can be used to personalize marketing campaigns by generating personalized messages, emails, and social media posts based on customer behavior and preferences.\n",
      "6. **Chatbots and Virtual Assistants**: Generative AI can power chatbots and virtual assistants, enabling businesses to provide 24/7 customer support and answer frequently asked questions.\n",
      "7. **Financial Analysis**: Generative AI can be used to analyze large datasets of financial transactions, identify patterns, and predict future trends, helping businesses make informed investment decisions.\n",
      "8. **Supply Chain Optimization**: Generative AI can be used to optimize supply chain operations by predicting demand, managing inventory, and streamlining logistics.\n",
      "9. **Data Annotation**: Generative AI can assist in annotating large datasets with labels, making it easier for machine learning models to learn from the data.\n",
      "10. **Predictive Maintenance**: Generative AI can be used to predict equipment failures and maintenance needs, reducing downtime and improving overall efficiency.\n",
      "\n",
      "In terms of specific industries, generative AI is being applied in:\n",
      "\n",
      "1. **Healthcare**: Generating medical images, predicting patient outcomes, and analyzing medical data.\n",
      "2. **Retail**: Creating personalized product recommendations, generating content for social media campaigns, and optimizing inventory management.\n",
      "3. **Education**: Personalized learning platforms, adaptive assessments, and generating educational content.\n",
      "4. **Manufacturing**: Predictive maintenance, quality control, and generating designs for new products.\n",
      "5. **Finance**: Risk analysis, portfolio optimization, and automating trading decisions.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses across various industries.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative Artificial Intelligence (AI) has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Generation**: Generative AI can create high-quality content such as articles, social media posts, product descriptions, and more. This helps businesses streamline their content creation process and improve the efficiency of their marketing teams.\n",
      "2. **Image and Video Creation**: Generative AI can generate images and videos that are indistinguishable from those created by humans. Businesses can use this technology to create high-quality visual content for social media, advertising, and product showcases.\n",
      "3. **Chatbots and Customer Service**: Generative AI-powered chatbots can provide personalized customer service, answer frequently asked questions, and even resolve simple issues on their own. This helps businesses reduce the burden of human customer support agents and improve customer satisfaction.\n",
      "4. **Data Analysis and Visualization**: Generative AI can analyze large datasets and generate insights and visualizations that help businesses make data-driven decisions. This technology is particularly useful for industries such as finance, healthcare, and retail.\n",
      "5. **Predictive Maintenance**: Generative AI can analyze sensor data from equipment and predict when maintenance is required, helping businesses reduce downtime and improve overall efficiency.\n",
      "6. **Product Design and Development**: Generative AI can assist in the design and development of new products by generating ideas, prototypes, and even final designs. This technology is particularly useful for industries such as aerospace, automotive, and consumer electronics.\n",
      "7. **Marketing Personalization**: Generative AI can analyze customer data and generate personalized marketing campaigns that are tailored to individual customers' needs and preferences.\n",
      "8. **Language Translation**: Generative AI-powered translation tools can help businesses communicate with international customers and partners more effectively, reducing the need for human translators.\n",
      "9. **Automated Transcription**: Generative AI can transcribe audio and video recordings quickly and accurately, helping businesses streamline their meeting notes, podcasting, and transcription needs.\n",
      "10. **Creative Writing**: Generative AI-powered writing tools can assist writers in generating ideas, completing projects, or even creating entire articles and blog posts.\n",
      "\n",
      "Some of the key industries where Generative AI is being applied include:\n",
      "\n",
      "* E-commerce\n",
      "* Healthcare\n",
      "* Finance\n",
      "* Marketing\n",
      "* Media and Entertainment\n",
      "* Education\n",
      "* Retail\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses in the years to come.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Creation**: Generate high-quality content such as articles, social media posts, and product descriptions, saving time and cost on human writers and editors.\n",
      "2. **Product Design**: Use generative models to design unique products, packaging, and branding materials, reducing the need for iterative iterations and costly revisions.\n",
      "3. **Marketing Automation**: Develop chatbots, email templates, and ad copy using generative AI, increasing lead generation and conversion rates.\n",
      "4. **Data Analysis**: Generate insights and forecasts on large datasets using generative AI models, enabling businesses to make informed decisions faster.\n",
      "5. **Cybersecurity**: Develop predictive models for threat detection and vulnerability assessment, minimizing the risk of cyber attacks and data breaches.\n",
      "6. **Image and Video Processing**: Utilize generative adversarial networks (GANs) to generate realistic images and videos, enhancing image recognition, object detection, and facial analysis applications.\n",
      "7. **Personalization**: Generate customized product recommendations, pricing, and sales scripts tailored to individual customers' preferences, increasing customer satisfaction and loyalty.\n",
      "8. **Customer Service**: Develop AI-powered chatbots that can understand and respond to complex customer inquiries in real-time, improving customer experience and reducing support costs.\n",
      "9. **Business-to-Business (B2B) Matching**: Generate high-quality business leads through AI-driven suggestion systems, saving sales teams time and effort.\n",
      "10. **Influencer Identification**: Use generative models to identify potential influencers across social media platforms, streamlining the influencer discovery and partnerships process.\n",
      "11. **Music Generation**: Create new music tracks using generative algorithms, opening up new opportunities for musicians, producers, and content creators.\n",
      "12. **Film and Video Production**: Generate high-quality visuals, titles, or sound effects to enhance film and video productions, reducing costs and increasing creative freedom.\n",
      "13. **Fashion Design**: Develop AI-powered fashion design tools that generate patterns, fabrics, and product designs, accelerating the fashion development process.\n",
      "14. **Speech Generation**: Utilize generative models to create human-like speech for public announcements, commercials, or voice assistants, enhancing audio content quality.\n",
      "15. **Risk Analysis**: Generate predictive models to identify potential risks and opportunities in various industries, enabling informed business decisions.\n",
      "\n",
      "These applications demonstrate the versatility of Generative AI across different sectors, revolutionizing various aspects of business operations and decision-making processes.\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling aabd4debf0c8... 100% ▕████████████████▏ 1.1 GB                         \n",
      "pulling 369ca498f347... 100% ▕████████████████▏  387 B                         \n",
      "pulling 6e4c38e1172f... 100% ▕████████████████▏ 1.1 KB                         \n",
      "pulling f4d24e9138dd... 100% ▕████████████████▏  148 B                         \n",
      "pulling a85fe2a2e58e... 100% ▕████████████████▏  487 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, I need to figure out how to explain the key components of Large Language Models (LLMs) as defined by some sources. The user asked specifically for definitions of \"neural network,\" \"attention,\" and \"transformer.\" \n",
      "\n",
      "First, for the neural network part. From what I remember, LLMs are built using neural networks, which are a type of machine learning model inspired by the structure of the human brain's neurons. Each layer in the network processes information through weights and biases to make predictions or generate outputs.\n",
      "\n",
      "Wait, but maybe I'm mixing up things. So, perhaps it's more about how they're structured as statistical models instead of just computation. They have layers that receive inputs and pass probabilities along, adjusting based on observed data.\n",
      "\n",
      "How many layers do LLMs typically have? I think there are usually several hundreds or thousands of these layers, allowing them to capture long-range dependencies in text. That makes sense because real language is context-specific over a large extent.\n",
      "\n",
      "Next up is attention. I recall that attention mechanisms allow models to focus on specific parts of the input when processing sequences. It's like assigning importance scores to different words or tokens based on their relevance. This helps the model make better decisions by paying more attention to the most relevant information.\n",
      "\n",
      "But how does it work exactly? Each token in the sequence is mapped through an encoder, which produces a vector. Then, this representation is input into an attention layer where each position can attend to all others—so perhaps using something like softmax or another normalization.\n",
      "\n",
      "What differentiates \"perplexity\" from actual word alignment? Perplexity measures how well a probability distributioned model predicts the next word in a sequence. While it's related, perplexity isn't just about matching words; it's about prediction accuracy, so I should mention that as a separate concept.\n",
      "\n",
      "Now onto the transformer itself. It was introduced by Vaswani et al., right? The core idea is self-attention, where each token can attend to all other tokens in the sequence. This mutual dependency allows the model to learn contextual representations of words in a way that's invariant to permutation (since attention doesn't care about input order). \n",
      "\n",
      "I should explain how the transformer processes text by embedding sequences into vectors and performing parallel operations on these embeddings for each token, which helps handle context effectively. Also, important applications include summarization, translation, and more.\n",
      "\n",
      "Putting it all together, I can outline each component with their definitions, the number of layers in an LLM (hundreds or more), and how attention and transformers enable their unique capabilities without explicit reasoning through them too much.\n",
      "</think>\n",
      "\n",
      "Large Language Models (LLMs) are a class of Artificial Intelligence models designed to simulate human-level language comprehension and production. Here's a detailed explanation of some core concepts behind LLMs:\n",
      "\n",
      "### 1. Neural Network\n",
      "LLMs are built upon neural networks, which are computational models inspired by the structure of the human brain. These networks consist of layers that process input information and learn representations through weights and biases. Each layer in an LLM takes inputs, applies transformations (represented by matrices of weights), and uses non-linear activation functions to produce outputs.\n",
      "\n",
      "In LLMs:\n",
      "- **Layers**: Typically hundreds or thousands of layers are used to capture long-range dependencies in text.\n",
      "- **Neural Networks**: They do not follow the classical computation framework; instead, they are probabilistic models that represent probabilities through their hidden states. Each layer adjusts these probabilities based on the input data.\n",
      "\n",
      "### 2. Attention\n",
      "Attention is a crucial component within LLMs that enables them to focus on specific parts of the input when processing sequences. Instead of passing probabilities along each step, the model assigns importance scores (weights) to each token in the sequence. This allows the model to attend to all positions simultaneously, enabling it to pay attention to different parts of the input as needed.\n",
      "\n",
      "- **How Attention Works**: The encoder produces an embedding for each token and passes its vector through an attention layer where every position can attend to all other positions. This is often implemented using mechanisms like softmax or a more sophisticated normalization.\n",
      "- **Perplexity vs Word Alignment**: Perplexity measures how well a language model predicts the next word in a sequence, while alignment refers to actual matching of words between inputs and outputs.\n",
      "\n",
      "### 3. Transformer\n",
      "TheTransformer introduced by Vaswani et al. is a revolutionary architecture for NLP due to its self-attention mechanism and parallel processing of tokens in a single layer.\n",
      "\n",
      "- **Self-Accociation**: Each token can attend to all other tokens, resulting in mutual dependency between the transformations of each token.\n",
      "- **Masking**: The model uses masks to guide it, ensuring lower-dimensional representations even when sequences are variable length or contain padding.\n",
      "- **Parallel Processing**: Tokens are processed simultaneously within a single layer, significantly enhancing their ability to capture contextual information and avoid word-based reasoning.\n",
      "\n",
      "### Summary\n",
      "LLMs like the BERT seq2seq and GPT are powerful because they efficiently capture long-range dependencies through parallel operations and self-attention.\n"
     ]
    }
   ],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
