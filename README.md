# LLM Engineering - Master AI and LLMs

Welcome! This repository documents my journey in learning Large Language Models (LLMs) and Generative AI. Each folder represents a step in my hands-on exploration of LLMs, from web automation and UI apps to fine-tuning, retrieval-augmented generation, and building agentic AI systems. The projects build on each other, reflecting both my progress and the evolving landscape of GenAI.

## Repository Structure

- **1_llm_web_automation/**: Web automation and scraping projects using LLMs, including tools for summarizing and extracting information from websites. This section explores the fundamentals of combining web scraping with AI, demonstrating how to fetch data from websites, process it with LLMs, and create automated workflows. I worked with libraries like BeautifulSoup and requests alongside OpenAI and Ollama APIs to build intelligent web tools. Projects include website summarizers, content extractors, and automated data collection systems that showcase practical applications of LLMs in web automation. The skills developed here form the foundation for more complex AI-powered applications.

- **2_web_ui_llm_apps/**: Interactive web UI applications powered by LLMs, featuring chatbots, assistants, and creative generators with Gradio interfaces. This section focuses on creating user-friendly interfaces for LLM applications, showing how to build interactive web applications that can engage with users in real-time. I worked with Gradio to create beautiful, responsive UIs for chatbots, creative writing assistants, and specialized AI tools. The projects demonstrate how to integrate multiple AI models, handle user input/output, and create engaging user experiences. This builds on the web automation skills and introduces frontend development concepts for AI applications.

- **3_huggingface_local_models/**: Experiments with running and using HuggingFace models locally, including pipelines, tokenizers, and model management. This section dives deep into the HuggingFace ecosystem, exploring how to work with open-source models directly on your machine without relying on cloud APIs. I learned about model pipelines, tokenization, text generation, and how to fine-tune models for specific tasks. The projects include building a meeting minutes generator and exploring different model architectures, providing hands-on experience with the tools that power modern AI applications. This knowledge is crucial for understanding how LLMs work under the hood and for building cost-effective AI solutions.

- **4_llm_code_generation/**: LLM-powered code generation, optimization, and analysis, with examples in Python and C++. This section explores how AI can assist in software development, demonstrating how to use LLMs for code generation, debugging, optimization, and analysis. I worked with both Python and C++ codebases, learning how to prompt LLMs effectively for different programming languages and tasks. Projects include code optimization, automated testing, and intelligent code analysis tools that can help developers write better, more efficient code. This builds on the understanding of LLMs and applies it to practical software development scenarios.

- **5_rag_knowledge_management/**: Retrieval Augmented Generation (RAG) systems for knowledge management, including vector stores and knowledge base integration. This section explores one of the most powerful techniques in modern AI: combining LLMs with external knowledge bases to create more accurate and contextual responses. I learned about vector databases, embedding models, semantic search, and how to build systems that can access and reason over large amounts of information. Projects include building a company knowledge management system and creating AI assistants that can answer questions based on specific documents. This knowledge is essential for building AI applications that need to work with real-world data and provide accurate, up-to-date information.

- **6_llm_fine_tuning_pricing/**: Fine-tuning LLMs for product pricing tasks, with datasets, scripts, and evaluation notebooks. This section explores how to customize pre-trained models for specific business applications, focusing on the complete fine-tuning pipeline from data preparation to model deployment. I learned about dataset creation, model training, evaluation metrics, and how to optimize models for specific tasks like pricing optimization. The projects demonstrate how to build AI systems that can understand business logic and make intelligent pricing decisions. This represents a significant step up in complexity and shows how to create specialized AI models for real-world business problems.

- **7_open_source_fine_tuning/**: Fine-tuning open-source LLMs for pricing and business applications, with a focus on reproducibility and open tools. This section builds on the fine-tuning concepts but focuses specifically on open-source models and tools, exploring how to work with models like Llama and Mistral. I learned about different fine-tuning techniques, including LoRA and QLoRA, and how to optimize models for efficiency and performance. The projects emphasize reproducibility and open-source best practices, showing how to create models that can be shared and deployed across different environments. This knowledge is crucial for building AI systems that don't rely on proprietary APIs and can be customized for specific business needs.

- **8_agentic_ai_deal_hunting/**: Agentic AI systems for autonomous deal hunting, featuring multi-agent architectures, planning, and cloud deployment. This section represents the culmination of all previous learning, exploring how to build complex, autonomous AI systems that can work independently to achieve business objectives. I learned about multi-agent architectures, autonomous planning, tool usage, and how to deploy AI systems in cloud environments. The projects include building a complete deal-hunting system that can search for opportunities, analyze them, and take actions autonomously. This demonstrates the full potential of modern AI systems and shows how to build applications that can operate independently in real-world scenarios.

- **9_advanced_ai_trading/**: Advanced AI applications in trading and finance, including fine-tuned models for trading strategy generation and cryptocurrency signal analysis. This section explores cutting-edge applications of AI in the financial domain, demonstrating how to build sophisticated trading systems that can generate strategies, analyze market data, and provide trading signals. I worked with multiple AI models (GPT-4, Claude, Gemini) to create diverse trading strategies and learned how to fine-tune models specifically for financial applications. Projects include building a complete fine-tuning pipeline for trading code generation and creating real-time cryptocurrency analysis systems. This represents advanced applications of AI in a high-stakes domain and demonstrates how to build systems that can make intelligent financial decisions.
